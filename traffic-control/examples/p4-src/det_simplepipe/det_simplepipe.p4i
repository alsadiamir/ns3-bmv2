# 1 "det_simplepipe.p4"
# 1 "<built-in>"
# 1 "<command-line>"
# 1 "det_simplepipe.p4"
/***
 * ================
 * Author: Sam Gao
 * Year:   2021
 * ================
 ***/

// A simple p4 switch that simply spits out 5 32 bit values in response to a single 32 bit value arriving
// with ethertype 0x88b5 (IEEE Std 802 - Local Experimental Ethertype 1).

# 1 "/usr/share/p4c/p4include/core.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* This is the P4-16 core library, which declares some built-in P4 constructs using P4 */




/// Standard error codes.  New error codes can be declared by users.
error {
    NoError, /// No error.
    PacketTooShort, /// Not enough bits in packet for 'extract'.
    NoMatch, /// 'select' expression has no matches.
    StackOutOfBounds, /// Reference to invalid element of a header stack.
    HeaderTooShort, /// Extracting too many bits into a varbit field.
    ParserTimeout, /// Parser execution time limit exceeded.
    ParserInvalidArgument /// Parser operation was called with a value
                           /// not supported by the implementation.
}

extern packet_in {
    /// Read a header from the packet into a fixed-sized header @hdr and advance the cursor.
    /// May trigger error PacketTooShort or StackOutOfBounds.
    /// @T must be a fixed-size header type
    void extract<T>(out T hdr);
    /// Read bits from the packet into a variable-sized header @variableSizeHeader
    /// and advance the cursor.
    /// @T must be a header containing exactly 1 varbit field.
    /// May trigger errors PacketTooShort, StackOutOfBounds, or HeaderTooShort.
    void extract<T>(out T variableSizeHeader,
                    in bit<32> variableFieldSizeInBits);
    /// Read bits from the packet without advancing the cursor.
    /// @returns: the bits read from the packet.
    /// T may be an arbitrary fixed-size type.
    T lookahead<T>();
    /// Advance the packet cursor by the specified number of bits.
    void advance(in bit<32> sizeInBits);
    /// @return packet length in bytes.  This method may be unavailable on
    /// some target architectures.
    bit<32> length();
}

extern packet_out {
    /// Write @hdr into the output packet, advancing cursor.
    /// @T can be a header type, a header stack, a header_union, or a struct
    /// containing fields with such types.
    void emit<T>(in T hdr);
}

// TODO: remove from this file, convert to built-in
/// Check a predicate @check in the parser; if the predicate is true do nothing,
/// otherwise set the parser error to @toSignal, and transition to the `reject` state.
extern void verify(in bool check, in error toSignal);

/// Built-in action that does nothing.
@noWarn("unused")
action NoAction() {}

/// Standard match kinds for table key fields.
/// Some architectures may not support all these match kinds.
/// Architectures can declare additional match kinds.
match_kind {
    /// Match bits exactly.
    exact,
    /// Ternary match, using a mask.
    ternary,
    /// Longest-prefix match.
    lpm
}
# 12 "det_simplepipe.p4" 2
// #include <v1model.p4>
# 1 "v1model.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* P4-16 declaration of the P4 simple pipe */




# 1 "/usr/share/p4c/p4include/core.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* This is the P4-16 core library, which declares some built-in P4 constructs using P4 */
# 23 "v1model.p4" 2

match_kind {
    range,
    // Either an exact match, or a wildcard (matching any value).
    optional,
    // Used for implementing dynamic_action_selection
    selector
}

@metadata @name("standard_metadata")
struct standard_metadata_t {
    //
    // Inputs
    //
    /* qdepth:
     * The instantaneous size of the queue. Note that this is
     * not measured in bytes. Here is the equation that converts
     * qdepth_bytes to qdepth:
     *     qdepth = qdepth_bytes/maxSizeBytes * (2^qsizeBits - 1)
     * Where maxSizeBytes is the maximum size of the queue in bytes,
     * and qsizeBits is the number of bits that are used to represent
     * size (both queue and packet). qsizeBits is a configurable
     * parameter for the p4-queue-disc module in ns3-bmv2.
     */
    bit<32> qdepth;
    /* qdepth_bytes:
     * The instantaneous size of the queue in bytes.
     */
    bit<32> qdepth_bytes;
    /* avg_qdepth:
     * The EWMA of the queue size. Computed using the same technique
     * as the RED queue disc implementation. Again, note that this is
     * not measured in bytes, but rather is mapped into an integer in
     * the range [0, 2^qsizeBits - 1]. See the description of the qdepth
     * field for an equation to convert bytes to an integer in this range.
     */
    bit<32> avg_qdepth;
    /* avg_qdepth_bytes:
     * The EWMA of the queue size in bytes.
     */
    bit<32> avg_qdepth_bytes;
    /* timestamp:
     * The time that the packet arrived, measured in nanoseconds.
     */
    bit<64> timestamp;
    /* idle_time:
     * The time when the queue last went empty, measured in nanoseconds.
     */
    bit<64> idle_time;
    /* qlatency:
     * The latest queue latency measurement. Determined by computing the
     * difference between the enqueue and dequeue timestamps for each
     * packet. Measured in nanoseconds.
     */
    bit<64> qlatency;
    /* avg_deq_rate_bytes:
     * The average queue service rate, measured in bytes/sec.
     */
    bit<32> avg_deq_rate_bytes;
    /* pkt_len:
     * The length of the packet. Note that this is not measured in bytes.
     * The packet length is transformed into an integer in the range
     * [0, 2^qsizeBits - 1] so that it is directly comparable to the 
     * qdepth and avg_qdepth fields.
     */
    bit<32> pkt_len;
    /* pkt_len_bytes:
     * Length of the packet in bytes.
     */
    bit<32> pkt_len_bytes;
    /* l3_proto:
     * The L3 protocol number (IPv4, IPv6, etc.)
     */
    bit<16> l3_proto;
    /* flow_hash:
     * A hash of identifying packet fields, e.g. the 5-tuple. Can be used
     * to identify flows.
     */
    bit<32> flow_hash;
    /* ingress_trigger:
     * Indicates that this is an ingress packet.
     */
    bit<1> ingress_trigger;
    /* timer_trigger:
     * Indicates that this packet was generated by a timer event.
     */
    bit<1> timer_trigger;
    //
    // Drop trigger metadata
    //
    /* drop_trigger:
     * Indicates that a drop event has occured and the drop metadata fields
     * have been populated.
     */
    bit<1> drop_trigger;
    /* drop_timestamp:
     * Timstamp (in ns) indicating when the drop event occured.
     */
    bit<64> drop_timestamp;
    /* drop_qdepth:
     * Instantaneous size of the queue when the packet was dropped.
     * Units are the same as the qdepth field above.
     */
    bit<32> drop_qdepth;
    /* drop_qdepth_bytes:
     * Instantaneous size of the queue (in bytes) when the packet was
     * dropped.
     */
    bit<32> drop_qdepth_bytes;
    /* drop_avg_qdepth:
     * EWMA of the qdepth when the packet was dropped. Units are the
     * same as the avg_qdepth field above.
     */
    bit<32> drop_avg_qdepth;
    /* drop_avg_qdepth_bytes:
     * EWMA of the qdepth (in bytes) when the packet was dropped.
     */
    bit<32> drop_avg_qdepth_bytes;
    /* drop_pkt_len:
     * Length of the dropped packet. Units are the same as the pkt_len
     * field above.
     */
    bit<32> drop_pkt_len;
    /* drop_pkt_len_bytes:
     * Length of the dropped packet (in bytes).
     */
    bit<32> drop_pkt_len_bytes;
    /* drop_l3_proto:
     * L3 protocol number of the dropped packet.
     */
    bit<16> drop_l3_proto;
    /* drop_flow_hash:
     * A hash of identifying packet fields, e.g. the 5-tuple, in the dropped
     * packet. Can be used to identify flows.
     */
    bit<32> drop_flow_hash;
    //
    // Enqueue trigger metadata
    //
    /* enq_trigger:
     * Indicates that an enqueue event has occured and the enqueue metadata fields
     * have been populated.
     */
    bit<1> enq_trigger;
    /* enq_timestamp:
     * Timstamp (in ns) indicating when the enqueue event occured.
     */
    bit<64> enq_timestamp;
    /* enq_qdepth:
     * Instantaneous size of the queue when the packet was enqueued.
     * Units are the same as the qdepth field above.
     */
    bit<32> enq_qdepth;
    /* enq_qdepth_bytes:
     * Instantaneous size of the queue (in bytes) when the packet was
     * enqueued.
     */
    bit<32> enq_qdepth_bytes;
    /* enq_avg_qdepth:
     * EWMA of the qdepth when the packet was enqueued. Units are the
     * same as the avg_qdepth field above.
     */
    bit<32> enq_avg_qdepth;
    /* enq_avg_qdepth_bytes:
     * EWMA of the qdepth (in bytes) when the packet was enqueued.
     */
    bit<32> enq_avg_qdepth_bytes;
    /* enq_pkt_len:
     * Length of the enqueued packet. Units are the same as the pkt_len
     * field above.
     */
    bit<32> enq_pkt_len;
    /* enq_pkt_len_bytes:
     * Length of the enqueued packet (in bytes).
     */
    bit<32> enq_pkt_len_bytes;
    /* enq_l3_proto:
     * L3 protocol number of the enqueued packet.
     */
    bit<16> enq_l3_proto;
    /* enq_flow_hash:
     * A hash of identifying packet fields, e.g. the 5-tuple, in the enqueued
     * packet. Can be used to identify flows.
     */
    bit<32> enq_flow_hash;
    //
    // Dequeue trigger metadata
    //
    /* deq_trigger:
     * Indicates that a dequeue event has occured and the dequeue metadata
     * has been populated.
     */
    bit<1> deq_trigger;
    /* deq_enq_timestamp:
     * Timestamp indicating when the dequeued packet was enqueued.
     */
    bit<64> deq_enq_timestamp;
    /* deq_qdepth:
     * Instantaneous size of the queue when the packet was dequeued.
     * Units are the same as the qdepth field above.
     */
    bit<32> deq_qdepth;
    /* deq_qdepth_bytes:
     * Instantaneous size of the queue (in bytes) when the packet was
     * dequeued.
     */
    bit<32> deq_qdepth_bytes;
    /* deq_avg_qdepth:
     * EWMA of the qdepth when the packet was dequeued. Units are the
     * same as the avg_qdepth field above.
     */
    bit<32> deq_avg_qdepth;
    /* deq_avg_qdepth_bytes:
     * EWMA of the qdepth (in bytes) when the packet was dequeued.
     */
    bit<32> deq_avg_qdepth_bytes;
    /* deq_timestamp:
     * Timstamp (in ns) indicating when packet was dequeued.
     */
    bit<64> deq_timestamp;
    /* deq_pkt_len:
     * Length of the dequeued packet. Units are the same as the pkt_len
     * field above.
     */
    bit<32> deq_pkt_len;
    /* deq_pkt_len_bytes:
     * Length of the dequeued packet (in bytes).
     */
    bit<32> deq_pkt_len_bytes;
    /* deq_l3_proto:
     * L3 protocol number of the dequeued packet.
     */
    bit<16> deq_l3_proto;
    /* deq_flow_hash:
     * A hash of identifying packet fields, e.g. the 5-tuple, in the dequeued
     * packet. Can be used to identify flows.
     */
    bit<32> deq_flow_hash;
    //
    // Outputs
    //
    /* drop:
     * If set then p4-queue-disc will drop the packet.
     */
    bit<1> drop;
    /* mark:
     * If set then p4-queue-disc will mark the packet (e.g. set ECN bit).
     */
    bit<1> mark;
    //
    // Inputs / Outputs
    //
    /* tarce_vars:
     * These are intended to be used for debugging purposes. The p4-queue-disc
     * has attached trace sources to these fields so that NS3 user scripts
     * can attach trace sinks to them can hence can track all changes made to
     * them. 
     */
    bit<32> trace_var1;
    bit<32> trace_var2;
    bit<32> trace_var3;
    bit<32> trace_var4;

    /// Error produced by parsing
    error parser_error;
}

enum CounterType {
    packets,
    bytes,
    packets_and_bytes
}

enum MeterType {
    packets,
    bytes
}

extern counter {
    counter(bit<32> size, CounterType type);
    void count(in bit<32> index);
}

extern direct_counter {
    direct_counter(CounterType type);
    void count();
}

extern meter {
    meter(bit<32> size, MeterType type);
    void execute_meter<T>(in bit<32> index, out T result);
}

extern direct_meter<T> {
    direct_meter(MeterType type);
    void read(out T result);
}

extern register<T> {
    register(bit<32> size);
    void read(out T result, in bit<32> index);
    void write(in bit<32> index, in T value);
}

// used as table implementation attribute
extern action_profile {
    action_profile(bit<32> size);
}

// Get a random number in the range lo..hi
extern void random<T>(out T result, in T lo, in T hi);
// If the type T is a named struct, the name is used
// to generate the control-plane API.
extern void digest<T>(in bit<32> receiver, in T data);

enum HashAlgorithm {
    crc32,
    crc32_custom,
    crc16,
    crc16_custom,
    random,
    identity,
    csum16,
    xor16
}

extern void mark_to_drop();
extern void hash<O, T, D, M>(out O result, in HashAlgorithm algo, in T base, in D data, in M max);

extern action_selector {
    action_selector(HashAlgorithm algorithm, bit<32> size, bit<32> outputWidth);
}

enum CloneType {
    I2E,
    E2E
}

@deprecated("Please use verify_checksum/update_checksum instead.")
extern Checksum16 {
    Checksum16();
    bit<16> get<D>(in D data);
}

/**
Verifies the checksum of the supplied data.
If this method detects that a checksum of the data is not correct it
sets the standard_metadata checksum_error bit.
@param T          Must be a tuple type where all the fields are bit-fields or varbits.
                  The total dynamic length of the fields is a multiple of the output size.
@param O          Checksum type; must be bit<X> type.
@param condition  If 'false' the verification always succeeds.
@param data       Data whose checksum is verified.
@param checksum   Expected checksum of the data; note that is must be a left-value.
@param algo       Algorithm to use for checksum (not all algorithms may be supported).
                  Must be a compile-time constant.
*/
extern void verify_checksum<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);
/**
Computes the checksum of the supplied data.
@param T          Must be a tuple type where all the fields are bit-fields or varbits.
                  The total dynamic length of the fields is a multiple of the output size.
@param O          Output type; must be bit<X> type.
@param condition  If 'false' the checksum is not changed
@param data       Data whose checksum is computed.
@param checksum   Checksum of the data.
@param algo       Algorithm to use for checksum (not all algorithms may be supported).
                  Must be a compile-time constant.
*/
extern void update_checksum<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

/**
Verifies the checksum of the supplied data including the payload.
The payload is defined as "all bytes of the packet which were not parsed by the parser".
If this method detects that a checksum of the data is not correct it
sets the standard_metadata checksum_error bit.
@param T          Must be a tuple type where all the fields are bit-fields or varbits.
                  The total dynamic length of the fields is a multiple of the output size.
@param O          Checksum type; must be bit<X> type.
@param condition  If 'false' the verification always succeeds.
@param data       Data whose checksum is verified.
@param checksum   Expected checksum of the data; note that is must be a left-value.
@param algo       Algorithm to use for checksum (not all algorithms may be supported).
                  Must be a compile-time constant.
*/
extern void verify_checksum_with_payload<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);
/**
Computes the checksum of the supplied data including the payload.
The payload is defined as "all bytes of the packet which were not parsed by the parser".
@param T          Must be a tuple type where all the fields are bit-fields or varbits.
                  The total dynamic length of the fields is a multiple of the output size.
@param O          Output type; must be bit<X> type.
@param condition  If 'false' the checksum is not changed
@param data       Data whose checksum is computed.
@param checksum   Checksum of the data.
@param algo       Algorithm to use for checksum (not all algorithms may be supported).
                  Must be a compile-time constant.
*/
extern void update_checksum_with_payload<T, O>(in bool condition, in T data, inout O checksum, HashAlgorithm algo);

extern void resubmit<T>(in T data);
extern void recirculate<T>(in T data);
extern void clone(in CloneType type, in bit<32> session);
extern void clone3<T>(in CloneType type, in bit<32> session, in T data);

extern void truncate(in bit<32> length);

// The name 'standard_metadata' is reserved

// Architecture.
// M should be a struct of structs
// H should be a struct of headers or stacks

parser Parser<H, M>(packet_in b,
                    out H parsedHdr,
                    inout M meta,
                    inout standard_metadata_t standard_metadata);

/* The only legal statements in the implementation of the
VerifyChecksum control are: block statements, calls to the
verify_checksum and verify_checksum_with_payload methods,
and return statements. */
control VerifyChecksum<H, M>(inout H hdr,
                             inout M meta);
@pipeline
control Ingress<H, M>(inout H hdr,
                      inout M meta,
                      inout standard_metadata_t standard_metadata);
@pipeline
control Egress<H, M>(inout H hdr,
                     inout M meta,
                     inout standard_metadata_t standard_metadata);

/* The only legal statements in the implementation of the
ComputeChecksum control are: block statements, calls to the
update_checksum and update_checksum_with_payload methods,
and return statements. */
control ComputeChecksum<H, M>(inout H hdr,
                              inout M meta);
@deparser
control Deparser<H>(packet_out b, in H hdr);

package V1Switch<H, M>(Parser<H, M> p,
                       VerifyChecksum<H, M> vr,
                       Ingress<H, M> ig,
                       Egress<H, M> eg,
                       ComputeChecksum<H, M> ck,
                       Deparser<H> dep
                       );
# 14 "det_simplepipe.p4" 2

// Needed before incuding stats_freq.p4.



# 1 "stat4.p4" 1
/***
 * ================
 * Author: Sam Gao
 * Year:   2021
 * ================
 ***/

// Library for in-switch computation of statistical measures of arbitrary distributions.
// In the following, we focus on frequency distributions, where each element of the 
// distributions represents the frequency of a value of interest extracted from
// packets. Non-frequency distributions can be easily supported by changing how N, 
// Xsum and Xsum_sq are updated. For further details, we refer to the paper 
//  "Sam Gao, Mark Handley, and Stefano Vissicchio. Stats 101 in P4: Towards 
// In-Switch Anomaly Detection. Proc. HotNets, 2021."


# 1 "/usr/share/p4c/p4include/core.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* This is the P4-16 core library, which declares some built-in P4 constructs using P4 */
# 18 "stat4.p4" 2
// #include <v1model.p4>
# 1 "v1model.p4" 1
/*
Copyright 2013-present Barefoot Networks, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/* P4-16 declaration of the P4 simple pipe */
# 20 "stat4.p4" 2

/***
 * stats_data:
 * [0]: N
 * [1]: Xsum = Ybar
 * [2]: Xsum_sq
 * [3]: Last clear request (initially 0).
 * where Y = NX. We can calculate Nx quite simply for any new x we want to compare
 * with the existing values, so this allows us to do comparisons.
 **
 * median_data:
 * [0]: Median bin
 * [1]: Higher-count.
 * [2]: Lower-count.
 ***/

register<bit<32>>(4 * 1) stats_data;
register<bit<32>>(4 * 1) median_data;
register<bit<16>>(600 * 1) stats_freq_internal;
register<bit<32>>(600 * 1) stats_last_clear;


action read_bucket(out bit<16> val, bit<32> idx, bit<32> counter_idx) {
    bit<32> val_write = (counter_idx * 600) + idx; // offset
    stats_freq_internal.read(val, val_write);
}

// zeros a single bucket, dropping its values from Xsum and Xsum_sq.
action drop_bucket(bit<32> idx, bit<32> counter_idx) {
    bit<32> val_write = (counter_idx * 600) + idx; // offset
    bit<32> data_offset = counter_idx * 4;
    bit<32> tmp;
    bit<16> val;
    stats_freq_internal.read(val, val_write);

    stats_data.read(tmp, data_offset);
    if (val > 0) {
        tmp = tmp - 1;
    }
    stats_data.write(data_offset, tmp);

    stats_data.read(tmp, data_offset + 1);
    tmp = tmp - (bit<32>)val;
    stats_data.write(data_offset + 1, tmp);

    stats_data.read(tmp, data_offset + 2);
    tmp = tmp - ((bit<32>)val * (bit<32>)val);
    stats_data.write(data_offset + 2, tmp);

    stats_freq_internal.write(val_write, 0);

    // Median updating.
    median_data.read(tmp, data_offset);
    bit<32> up;
    bit<32> down;
    median_data.read(up, data_offset + 1);
    median_data.read(down, data_offset + 2);
    if (idx < tmp) {
        // Modify bottom value.
        down = down - (bit<32>)val;
    } else if (idx > tmp) {
        // Modify top value.
        up = up - (bit<32>)val;
    }

    median_data.write(data_offset + 1, up);
    median_data.write(data_offset + 2, down);
}

// zeros all buckets, as well as the relevant sums.
action stats_clear(bit<32> counter_idx) {
    bit<32> data_offset = counter_idx * 4;

    stats_data.write(data_offset, 0);
    stats_data.write(data_offset + 1, 0);
    stats_data.write(data_offset + 2, 0);

    median_data.write(data_offset, 0);
    median_data.write(data_offset + 1, 0);
    median_data.write(data_offset + 2, 0);

    bit<32> ts;
    stats_data.read(ts, data_offset + 3);
    stats_data.write(data_offset + 3, ts + 1);
}

action stats_push_freq(out bit<16> freq_value, bit<32> idx, bit<32> counter_idx) {
    bit<32> val_write = (counter_idx * 600) + idx; // offset
    bit<32> tmp;
    bit<32> ts;
    bit<32> ts_actual;
    bit<32> data_offset = counter_idx * 4;

    // ** Critical section stat_data

    stats_data.read(tmp, data_offset + 1);
    tmp = tmp + 1;
    stats_data.write(data_offset + 1, tmp);

    stats_data.read(tmp, data_offset + 2);
    stats_freq_internal.read(freq_value, val_write);

    // Check if we need to clear the value before using it.
    stats_last_clear.read(ts_actual, val_write);
    stats_data.read(ts, data_offset + 3);
    if (ts_actual < ts) {
        freq_value = 0; // account for clear
    }
    stats_last_clear.write(val_write, ts);

    stats_freq_internal.write(val_write, freq_value + 1);

    /***
     * Derivation:
     * Xsum_sq_new = Xsum_sq - X^2 + (X + 1)^2
     *             = Xsum_sq + 2X + 1
     ***/
    tmp = tmp + (bit<32>)(freq_value * 16w2) + 32w1;
    stats_data.write(data_offset + 2, tmp);

    // Update N.
    stats_data.read(tmp, data_offset);
    if (freq_value == 0) { // new contender
        tmp = tmp + 1;
    }
    stats_data.write(data_offset, tmp);

    // Compute VarNX and StdNX in request instead to minimize time spent here.

    // Median updating.
    median_data.read(tmp, data_offset);
    bit<32> up;
    bit<32> down;
    median_data.read(up, data_offset + 1);
    median_data.read(down, data_offset + 2);
    if (idx < tmp) {
        // Increment bottom value if bumping below current median.
        down = down + 1;
    }
    if (idx > tmp) {
        // Increment top value if bumping above current median.
        up = up + 1;
    }
    median_data.write(data_offset + 1, up);
    median_data.write(data_offset + 2, down);
}

action median_tick(bit<32> counter_idx){
    bit<32> data_offset = counter_idx * 4;
    bit<32> tmp;
    bit<16> data;
    bit<32> up;
    bit<32> down;
    bit<2> dir = 0;

    median_data.read(tmp, data_offset);
    median_data.read(up, data_offset + 1);
    median_data.read(down, data_offset + 2);
    bit<32> val_read = (counter_idx * 600) + tmp; // offset

    stats_freq_internal.read(data, val_read);
    if (down > up + (bit<32>)data) {
        // Bottom heavy - move index down.
        tmp = tmp - 1;
        up = up + (bit<32>)data;
        dir = 1;
    }
    if (up > down + (bit<32>)data) {
        // Top heavy - move index up.
        tmp = tmp + 1;
        down = down + (bit<32>)data;
        dir = 2;
    }

    // Read new median bin - the index changed.
    val_read = (counter_idx * 600) + tmp;
    stats_freq_internal.read(data, val_read);
    if (dir == 1) {
        down = down - (bit<32>)data;
    }
    if (dir == 2) {
        up = up - (bit<32>)data;
    }
    median_data.write(data_offset, tmp);
    median_data.write(data_offset + 1, up);
    median_data.write(data_offset + 2, down);
}

action median_90_tick(bit<32> counter_idx){
    bit<32> data_offset = counter_idx * 4;
    bit<32> tmp;
    bit<16> data;
    bit<32> up;
    bit<32> down;
    bit<2> dir = 0;

    median_data.read(tmp, data_offset);
    median_data.read(up, data_offset + 1);
    median_data.read(down, data_offset + 2);
    bit<32> val_read = (counter_idx * 600) + tmp; // offset
    stats_freq_internal.read(data, val_read);

    if (down > 9*up + (bit<32>)data) {
        // Bottom heavy - move index down.
        tmp = tmp - 1;
        up = up + (bit<32>)data;
        dir = 1;
    }
    if (up > 9*down + (bit<32>)data) {
        // Top heavy - move index up.
        tmp = tmp + 1;
        down = down + (bit<32>)data;
        dir = 2;
    }

    // Read new median bin - the index changed.
    val_read = (counter_idx * 600) + tmp;
    stats_freq_internal.read(data, val_read);
    if (dir == 1) {
        down = down - (bit<32>)data;
    }
    if (dir == 2) {
        up = up - (bit<32>)data;
    }
    median_data.write(data_offset, tmp);
    median_data.write(data_offset + 1, up);
    median_data.write(data_offset + 2, down);
}

struct stats_t {
    bit<32> N;
    bit<32> Xsum;
    bit<32> Xsum_sq;
    bit<32> VarNX;
    bit<32> StdNX;
    bit<32> Median;
}

// Allows extracting the stats about the data currently pushed in so far.
action stats_get_data(out stats_t stat_struct, bit<32> counter_idx) {
    stats_data.read(stat_struct.N, (counter_idx * 4));
    stats_data.read(stat_struct.Xsum, (counter_idx * 4) + 1);
    stats_data.read(stat_struct.Xsum_sq, (counter_idx * 4) + 2);

    /***
    * Derivation:
    * Var(NX) = E[(NX)^2] - E[NX]^2
    *         = Sum((NX)^2)/N - (Xsum)^2
    *         = N^2/N Xsum_sq - (Xsum)^2
    *         = N(Xsum_sq) - (Xsum)^2
    ***/
    stat_struct.VarNX = stat_struct.N * stat_struct.Xsum_sq - (stat_struct.Xsum * stat_struct.Xsum);

    // Approximation of sqrt(N), similar to:
    // https://github.com/EOSIO/logchain/blob/master/doc/sqrt.md
    bit<32> stdY = stat_struct.VarNX;

    if (stdY > 1) {
        bit<8> msb_x = 0;
        // Unrolled MSB matching up to 2^31 -  this is probably slow.
        // We can use a LPM match table for this, but we don't have the luxury of jumping
        // into a table... There also aren't any P4 primitives for MSB matching, sadly.
        // De Bruijn also requires an LUT, and hence isn't applicable here (it would take
        // as much table space as an LPM).

        if (stdY & 0b10000000000000000000000000000000 != 0) msb_x = 31;
        else if (stdY & 0b1000000000000000000000000000000 != 0) msb_x = 30;
        else if (stdY & 0b100000000000000000000000000000 != 0) msb_x = 29;
        else if (stdY & 0b10000000000000000000000000000 != 0) msb_x = 28;
        else if (stdY & 0b1000000000000000000000000000 != 0) msb_x = 27;
        else if (stdY & 0b100000000000000000000000000 != 0) msb_x = 26;
        else if (stdY & 0b10000000000000000000000000 != 0) msb_x = 25;
        else if (stdY & 0b1000000000000000000000000 != 0) msb_x = 24;
        else if (stdY & 0b100000000000000000000000 != 0) msb_x = 23;
        else if (stdY & 0b10000000000000000000000 != 0) msb_x = 22;
        else if (stdY & 0b1000000000000000000000 != 0) msb_x = 21;
        else if (stdY & 0b100000000000000000000 != 0) msb_x = 20;
        else if (stdY & 0b10000000000000000000 != 0) msb_x = 19;
        else if (stdY & 0b1000000000000000000 != 0) msb_x = 18;
        else if (stdY & 0b100000000000000000 != 0) msb_x = 17;
        else if (stdY & 0b10000000000000000 != 0) msb_x = 16;
        else if (stdY & 0b1000000000000000 != 0) msb_x = 15;
        else if (stdY & 0b100000000000000 != 0) msb_x = 14;
        else if (stdY & 0b10000000000000 != 0) msb_x = 13;
        else if (stdY & 0b1000000000000 != 0) msb_x = 12;
        else if (stdY & 0b100000000000 != 0) msb_x = 11;
        else if (stdY & 0b10000000000 != 0) msb_x = 10;
        else if (stdY & 0b1000000000 != 0) msb_x = 9;
        else if (stdY & 0b100000000 != 0) msb_x = 8;
        else if (stdY & 0b10000000 != 0) msb_x = 7;
        else if (stdY & 0b1000000 != 0) msb_x = 6;
        else if (stdY & 0b100000 != 0) msb_x = 5;
        else if (stdY & 0b10000 != 0) msb_x = 4;
        else if (stdY & 0b1000 != 0) msb_x = 3;
        else if (stdY & 0b100 != 0) msb_x = 2;
        else if (stdY & 0b10 != 0) msb_x = 1;

        bit<8> msb_z = msb_x >> 1;
        bit<32> mantissa_mask = (32w1 << msb_x) - 1;
        bit<32> mantissa_z_hi = 0;
        if (msb_x & 1 != 0) {
            mantissa_z_hi = (32w1 << msb_z);
        }

        bit<32> mantissa_z_lo = (stdY & mantissa_mask) >> (msb_x - msb_z);
        stdY = (32w1 << msb_z) | ((mantissa_z_hi | mantissa_z_lo) >> 1);
    }
    stat_struct.StdNX = stdY;

    median_data.read(stat_struct.Median, (counter_idx * 4));
}
# 20 "det_simplepipe.p4" 2





// Counter indices.



// Other constants.






/* data types */
typedef bit<9> egressSpec_t;
typedef bit<48> macAddr_t;
typedef bit<32> ip4Addr_t;

/* headers */
header ethernet_t {
    macAddr_t dstAddr;
    macAddr_t srcAddr;
    bit<16> etherType;
}

header ipv4_t {
  bit<4> version;
  bit<4> ihl;
  bit<8> tos;
  bit<16> totalLen;
  bit<16> identification;
  bit<3> flags;
  bit<13> fragOffset;
  bit<8> ttl;
  bit<8> protocol;
  bit<16> hdrChecksum;
  ip4Addr_t srcAddr;
  ip4Addr_t dstAddr;
}

header tcp_t {
  bit<16> srcPort;
  bit<16> dstPort;
  bit<32> seqNo;
  bit<32> ackNo;
  bit<4> dataOffset;
  bit<4> reserved;
  bit<8> flags;
  bit<16> window;
  bit<16> csum;
  bit<16> urgPtr;
}


@name("headers")
struct headers {
    ethernet_t ethernet;
    // ipv4_t  ipv4;
    // tcp_t   tcp;
}

struct metadata {
    stats_t stats;
}


/* checksum */
control MyVerifyChecksum(inout headers hdr, inout metadata meta) {
    apply {
    }
}

control MyComputeChecksum(inout headers hdr, inout metadata meta) {
    apply {
    }
}


/* ingress */
control MyIngress(inout headers hdr,
                  inout metadata meta,
                  inout standard_metadata_t standard_metadata) {

    // The time-based sliding window is only used for top-level search.    
    register<bit<32>>(1) next_bucket;
    register<bit<64>>(1) last_bucket_stamp;
    register<bit<256>>(8) distinctFlows;
    register<bit<16>>(1) peak_packet_count;
    register<bit<32>>(1) peak_nval;


    apply {
        //trying anomaly now

        bit<64> bucket_stamp = (bit<64>) standard_metadata.timestamp >> 20;
        bit<64> last_stamp;
        bit<16> median;
        bit<16> atk_pkt_count = 0;
        bit<16> peak_pkt_count = 0;
        bit<32> peak = 0;

        if (hdr.ethernet.isValid()) {
            bit<16> tmp;
            bit<32> bucket_idx;
            next_bucket.read(bucket_idx, 0);

            //grab CVAL
            bit<16> cval;
            read_bucket(cval, bucket_idx, 0);
            stats_get_data(meta.stats, 0);

            //grab NVAL
            bit<32> nval = (bit<32>)cval * meta.stats.N;
            last_bucket_stamp.read(last_stamp, 0);

            //FLOW COUNTING
            bit<256> tmpDistinctFlowsByte;
            bit<256> tmpDistinctFlowsByteTmp;
            bit<1> tmpDistinctFlowsBit;
            bit<256> tmpDistinctFlowsCurrent;
            bit<8> hash_posix;
            bit<32> index;

            if (bucket_idx == 10) {
              bucket_idx = 0;
            }

            stats_get_data(meta.stats, 1);
            stats_freq_internal.read(tmp, (1 * 600) + meta.stats.Median);

            //register flows
            hash(index, HashAlgorithm.crc32, 32w0, {hdr.ethernet.srcAddr, hdr.ethernet.dstAddr}, 32w8);
            //hash and then put to data structure
            hash(hash_posix, HashAlgorithm.crc32, 32w0, {hdr.ethernet.srcAddr, hdr.ethernet.dstAddr}, 32w256);

            standard_metadata.trace_var1 = index;
            distinctFlows.read(tmpDistinctFlowsCurrent, index);
            tmpDistinctFlowsByte = tmpDistinctFlowsCurrent << hash_posix;
            tmpDistinctFlowsByte = tmpDistinctFlowsByte >> 255;

            if(tmpDistinctFlowsByte == 0){
              median_90_tick(1);
              stats_push_freq(tmp, bucket_idx, 1);
              tmpDistinctFlowsByte = 1;
              tmpDistinctFlowsByte = tmpDistinctFlowsByte << 255;
              tmpDistinctFlowsByte = tmpDistinctFlowsByte >> hash_posix;
              tmpDistinctFlowsCurrent = tmpDistinctFlowsCurrent + tmpDistinctFlowsByte;
              distinctFlows.write(index, tmpDistinctFlowsCurrent);
            }

            if (bucket_stamp > last_stamp) {
              //fix here
              distinctFlows.write(0,0);
              distinctFlows.write(1,0);
              distinctFlows.write(2,0);
              distinctFlows.write(3,0);
              distinctFlows.write(4,0);
              distinctFlows.write(5,0);
              distinctFlows.write(6,0);
              distinctFlows.write(7,0);

              // Current bucket interval elapsed. Finalize the bucket and increment.
              last_bucket_stamp.write(0, bucket_stamp);

              // Single-tail: only raise an alert if the amount of traffic is high.
              if (cval > 100 && nval > meta.stats.Xsum + (2 * meta.stats.StdNX)) { // compare Nx
                // Exceeds defined threshold.
                // Send digest so that the controller can populate the second counter.
                drop_bucket(bucket_idx, 0);
                if(hdr.ethernet.isValid()){
                  stats_freq_internal.read(median, (1 * 600) + meta.stats.Median);
                }
              }

              if(nval > peak){
                //every time a bigger nval is detected, we reset the peak count
                peak_nval.write(0, nval);
                peak_packet_count.write(0, 0);
              } else{
                if(peak_pkt_count == 0){
                  peak_packet_count.write(0, atk_pkt_count);
                }
              }

              // Push bucket.
              bucket_idx = bucket_idx + 1;
              // Wrap last bucket index around if window is full.
              if (bucket_idx == 10) {
                bucket_idx = 0;
              }
              // Ensure the new bucket is clean.
              drop_bucket(bucket_idx, 0);
              drop_bucket(bucket_idx, 1);
              next_bucket.write(0, bucket_idx);
            }

            // Increment the packets bucket
            stats_push_freq(tmp, bucket_idx, 0);
      }
    }
}

/* egress */
control MyEgress(inout headers hdr,
                 inout metadata meta,
                 inout standard_metadata_t standard_metadata) {
    apply { }
}

/* parsing */
parser MyParser(packet_in packet,
        out headers hdr,
        inout metadata meta,
        inout standard_metadata_t standard_metadata)
{
//   state start {
//     packet.extract(hdr.ethernet);
//     transition select(hdr.ethernet.etherType) {
//       TYPE_IPV4: ipv4;
//       default: accept;
//     }
//   }

//   state ipv4 {
//     packet.extract(hdr.ipv4);
//     transition select(hdr.ipv4.protocol) {
//       PROTO_TCP: tcp;
//       default: accept;
//     }
//   }

//   state tcp {
//     packet.extract(hdr.tcp);
//     transition accept;
//   }

    state start {
        packet.extract(hdr.ethernet);
        transition accept;
    }

}

control MyDeparser(packet_out packet, in headers hdr) {
    apply {
        packet.emit(hdr.ethernet);
        // packet.emit(hdr.ipv4);
        // packet.emit(hdr.tcp);
    }
}

/* switch v1 */
V1Switch(
    MyParser(),
    MyVerifyChecksum(),
    MyIngress(),
    MyEgress(),
    MyComputeChecksum(),
    MyDeparser()
) main;
